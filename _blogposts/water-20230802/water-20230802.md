---
title: NEP Machine Learning Potential Training for Room Temperature Water
date: 2023-08-02 10:41:45
collection: blogposts
permalink: /blogposts/water-20230802/water-20230802
thumbnail: /blogposts/water-20230802/water-virial-shift-imgs/snapshot.png
tags:
  - MLP
  - NEP
  - Water
categories: blog

---

# Show the complete training process

## 1. Training process 

1. In order to obtain a more reasonable training structure, VASP.6.4.1 was used to conduct AIMD-ML-NPT warming sampling at 298 K, with a step size of 0.25 fs, and a 10 w step simulation. (AIMD settings are provided in the appendix.)

2. Composition of training set:

   1）Obtain 100 training structures at regular intervals from the previous step；

   2） **5** structures were randomly selected from the AIMD trajectory, and **12** different degrees of deformation (**0.70 0.75 0.80 0.85 0.90 0.95 1.05 1.10 1.15 1.20 1.25 1.30**) were performed, and **a total of 60 structures** were obtained. This step of stretching and compression is for the stability of the potential function, especially if the trained NEP needs to adapt to structures with **different initial densities** (such as the density of water in the initial modeling structure is 0.6 g/cm^3) in MD Perform NPT simulation, this step can greatly **enhance the stability of the potential function**.

3. Train NEP on the above **160 structures**, and then do active learning, starting from the small cells of AIMD, continue active learning iterations, and the last two rounds of iterations are over, which can accurately predict the learning small cell system. Iterations of this small cell process added a total of **50**  structures.

4. Finally, the final total training structure is 100+60+50=230.(note: AIMD results were obtained using the **PAW_PBE H 15Jun2001** and **PAW_PBE O 08Apr2002** pseudopotentials in **AIMD_ML**.)

5. Open [**<font color='orange'>GPUMD</font>**](https://gpumd.org/), train **NEP**.(NEP training parameter settings are provided in the appendix.)

## 2. The influence of ENCUT on the convergence of Virial training

After completing the mediocre training above, I found that Virial cannot converge, **Pxx, Pyy, Pzz will always produce shift**. Then try to find out the reason (with the help of Dr. **Xu Nan and Dr. Fan Zheyong**).

1. For O_h, H_h pseudopotential, use ENCUT = 600. It was found that it was still unable to converge.

   

   <figure align="center">
     <img src="https://raw.githubusercontent.com/XiTanna/imags/main/water-virial-shift-imgs/water_virial_shift.png" alt="My Image" />
    <figcaption><strong>Fig.1 NEP Virial train</strong></figcaption>
   </figure>
   
   
2. Change O_h, H_h pseudopotential, use ENCUT=1000, compare force and virial, the difference in force is small, and the difference in virial is large. So far, it is guessed that a larger ENCUT is required to allow virial to converge.

   <figure align="center">
     <img src="https://raw.githubusercontent.com/XiTanna/imags/main/water-virial-shift-imgs/Force.png" alt="My Image" />
     <figcaption><strong>Fig.2 Comparison of single-point calculation results of force with different ENCUT values</strong></figcaption>
   </figure>

   <figure align="center">
     <img src="https://raw.githubusercontent.com/XiTanna/imags/main/water-virial-shift-imgs/virial.png" alt="My Image" />
     <figcaption><strong>Fig.3 Comparison of single-point calculation results of virial with different ENCUT values</strong></figcaption>
   </figure>

3. After completing all single-point calculations with ENCUT=1400, retrain NEP. Virial converges perfectly!

   <figure align="center">
     <img src="https://raw.githubusercontent.com/XiTanna/imags/main/water-virial-shift-imgs/water_virial_no_shift.png" alt="My Image" />
     <figcaption><strong>Fig.4 NEP virial train</strong></figcaption>
   </figure>
   
   
4. Finally, the NEP training and MD verification accuracy are shown in the figure below.

   <figure align="center">
     <img src="https://raw.githubusercontent.com/XiTanna/imags/main/water-virial-shift-imgs/check.png" alt="My Image" />
     <figcaption><strong>Fig.5 NEP training and MD verification accuracy</strong></figcaption>
   </figure>

**Note**: When training Virial, it is necessary to test the convergence of **ENCUT** to avoid invalid training caused by Virial shift!

## 3. NEP Machine Learning Potential Validation

In order to verify the accuracy of the trained machine learning potential, properties such as **RDF and density should be verified**.

1. **RDF**

   Compare the RDF of O-O, O-H and H-H of NEP-MD and AIMD, see the figure below.

   <figure align="center">
     <img src="https://raw.githubusercontent.com/XiTanna/imags/main/water-virial-shift-imgs/O-O.png" alt="My Image" />
     <figcaption><strong>Fig.6 RDF O-O</strong></figcaption>
   </figure>

   <figure align="center">
     <img src="https://raw.githubusercontent.com/XiTanna/imags/main/water-virial-shift-imgs/O-H.png" alt="My Image" />
     <figcaption><strong>Fig.7 RDF O-H</strong></figcaption>
   </figure>

   <figure align="center">
     <img src="https://raw.githubusercontent.com/XiTanna/imags/main/water-virial-shift-imgs/H-H.png" alt="My Image" />
     <figcaption><strong>Fig.8 RDF H-H</strong></figcaption>
   </figure>

2. **density**

   Density of water at 298K and 1atm：AIMD is**1.090 g/cm^3**，MD is **1.091 g/cm^3**. Here, we find that the density of water at room temperature predicted by NEP is consistent with AIMD. But there is still a little distance from the experimental value of 0.997. This gap may be a factor of DFT, which is determined by the functional.

In the end, we obtained the room temperature water NEP machine learning potential comparable to DFT accuracy with a very small training structure and computational load.

Our final training set and NEP potential can be downloaded [**<font color='orange'>here</font>**](https://github.com/XiTanna/MLP/tree/main/NEP_in_room_temperature_water) .

## Appendix 1: Simulation set up

1) **AIMD_ML_NPT**

   ```shell
   # basic parameters 
   SYSTEM       = AIMDML_NPTcooling
   #NCORE        = 28          # 8*?=? 
   #KPAR         = 4
   NPAR         = 2
   KGAMMA       = .TRUE.      # GAMMA point
   KSPACING     = 2.0         # to ensure that the k-mesh = 1*1*1, must test
   ENCUT        = 600.0       # to make the "Pullay stress" zero, a higher ENCUT is needed (>=600)  
   PREC         = Normal      # precision-mode
   GGA          = PE          # GGA = PE
   ISTART       = 0           # read the WAVECAR file or not (ICHARG=2) 
   LWAVE        = .FALSE.     # write WAVECAR or not 
   LCHARG       = .FALSE.     # write CHGCAR or not 
   
   IVDW         = 12
   
   # Electronic Relaxation    
   ISMEAR       = 0           # 0=Gaussian smearing. (1,2)=Methfessel-Paxton order N 
   SIGMA        = 0.05         # width of the smearing in eV 
   EDIFF        = 1E-5        # global break for electronic SC-loop
   #EDIFFG       = -1e-2      # break for force
   LREAL        = A           # projection operators
   NELM         = 120         # maximum number of electronic SC
   NELMIN       = 5           # avoid breaking after 2 steps  
   # Molecular Dynamics 
   IBRION       = 0           # Activate MD 
   MDALGO       = 3           # 2=Nose-Hoover, 3=Langevin 
   ISIF         = 3           # 1=NVE, 2=NVT, 3=NpT 
   #SMASS        = 3
   ALGO         = Normal      # Normal=IALGO=38 (Davidson), Fast=IALGO=48 (RMM-DIIS)
   ISYM         = 0           # no symmetry for MD, completely
   TEBEG        = 298         # Begin temperature K 
   TEEND        = 298         # Final temperature K 
   NSW          = 100000      # Max ionic steps
   POTIM        = 0.25           # Timestep in fs
   LANGEVIN_GAMMA = 10.0 10.0    # damp (ps-1) for atom degrees-of-freedom
   LANGEVIN_GAMMA_L = 10      # friction coefficient (ps-1) for lattice degrees-of-freedom 
   PMASS        = 1000        # fictitious mass (in amu) to lattice degrees-of-freedom 
   PSTRESS      = 1.01E-3     # controls the target pressure in AIMD
   NWRITE       = 1           # long MD-runs use NWRITE=0 or 1 
   NBLOCK       = 1           # write PCF and DOS, scale kinetic energy, also the output interval of XDATCAR 
   # Machine learning force field
   ML_LMLFF     = .TRUE.        # enables/disables the use of MLFF
   ML_MODE      = train         # MLFF method (or mode)
   ML_LBASIS_DISCARD = .FALSE.
   ML_MB        = 5000
   ```

2) **DFT_Single_Point**

   ```shell
   Systerm=water
   
   ENCUT=1200
   EDIFF=1E-6
   ISMEAR=0
   
   SIGMA=0.02
   
   KSPACING=0.2
   KGAMMA=.TRUE.
   
   NELM=120
   NELMIN=5
   
   IVDW=12
   
   ALGO=Normal
   PREC=Accurate
   LREAL=Auto
   
   GGA=PE
   NSW=0
   
   LWAVE=.FALSE.
   LCHARG=.FALSE.	
   ```

   

3) **NEP train set up**

   ```shell
   type       	2 O H  # this is a mandatory keyword
   version       4       # default
   cutoff        8 4     # default
   n_max         4 4     # default
   basis_size    12 12   # default
   l_max         4 2 0   # default
   neuron        30      # default
   lambda_e      1.0     # default
   lambda_f      1.0     # default
   lambda_v      0.1     # default
   batch         1000    # default
   population    50      # default
   generation    100000  # default
   ```

## Appendix 2: Scripts used during training

**1）Function:** Identify whether the single-point calculation is completed, and print the absolute path of the case if it is not completed or is wrong. (The script needs to **depend on ase**, after writing the path of the script to the environment variable, it can be executed anywhere)

```python
#!/home/xitan/.conda/envs/xitan_conda/bin/python

import os
import glob
import argparse

def check_vasp_completion(outcar_file):
    with open(outcar_file, 'r') as f:
        # read the last line of the file
        last_line = f.readlines()[-1]

    # Check that the last line contains "Voluntary context switches"
    if "Voluntary context switches" in last_line:
        print(f'{outcar_file} has finished.')
    else:
        print(f'{outcar_file} has not finished. Path: {os.path.abspath(outcar_file)}')


def main(args):
    outcar_folder = args.outcar_folder

    # Find all OUTCAR files by glob, including subdirectories
    outcar_files = glob.glob(f"{outcar_folder}/**/OUTCAR", recursive=True)

    for outcar_file in outcar_files:
        check_vasp_completion(outcar_file)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Check VASP completion.')
    parser.add_argument('outcar_folder', type=str, default=".", nargs='?', help='Path to the directory containing OUTCAR files. Default is current directory.')

    args = parser.parse_args()
    main(args)
```

**Usage:** Save this code as outcar_check, give permissions chmod +x outcar_check, then outcar_check casedir.

**Example:** outcar_check alloutcar.

**2）Function:** Put multiple completed single-point calculations into one folder to facilitate subsequent format conversion.

```shell
#!/bin/bash

dir_path="/data1/xitan/works/MLP-MD/NiHAB/sol/pure-water/h_poential/1400ev/deform"

new_dir_path="/data1/xitan/works/MLP-MD/NiHAB/sol/pure-water/h_poential/1400ev/all_outcar_deform"


mkdir -p $new_dir_path


counter=1

find $dir_path -type d -name '0' -exec rm -rf {} \;


find $dir_path -type f -name 'OUTCAR' | sort | while read -r file
do
    mkdir "$new_dir_path/$counter"
    cp "$file" "$new_dir_path/$counter"/OUTCAR


    ((counter++))
done

```

**Usage:** Save the above code as get_alloutcar.sh, and then modify two dirs. The first dir_path represents the file directory where the single point calculation is located, and the second directory is the save path.

**Example:** sh get_alloutcar.sh

**3）Function:** Convert multiple OUTCARs to nep's input format exyz, convert all outcars in 2) to a train.xyz, and identify whether the OUTCAR is correct, if the format is wrong, print the path where the wrong OUTCAR is located, and quickly locate to process.

```python
#!/home/xitan/.conda/envs/xitan_conda/bin/python
import os
import glob
import argparse
from ase import io
from tqdm import tqdm

def convert_all_outcars_to_xyz(outcar_folder, xyz_file):
    # Find all OUTCAR files by glob, including subdirectories
    outcar_files = glob.glob(f"{outcar_folder}/**/OUTCAR", recursive=True)
    print(f"Found {len(outcar_files)} OUTCAR files.")

    atoms_list = []
    
    # Use tqdm to display processing progress
    for outcar_file in tqdm(outcar_files, desc="Converting OUTCARs to exyz"):
        try:
            # Attempt to read atoms from OUTCAR file
            atoms = io.read(outcar_file, format='vasp-out')
            atoms_list.append(atoms)
        except Exception as e:
            print(f"Error reading file {outcar_file}: {e}")
            return  # Stop the execution if an error occurs

    # Write all atom information to an xyz file
    io.write(xyz_file, atoms_list, format='extxyz')

    print(f"All OUTCAR files have been converted into {xyz_file}.")

# Processing command-line arguments with argparse
parser = argparse.ArgumentParser(description='Convert OUTCAR files to exyz format.')
parser.add_argument('-i', '--input', default='alloutcar',
                    help='Input directory containing OUTCAR files. Default is "alloutcar".')
parser.add_argument('-o', '--output', default='train.xyz',
                    help='Output filename for the exyz file. Default is "train.xyz".')

args = parser.parse_args()

convert_all_outcars_to_xyz(args.input, args.output)
```

Same as 1), after the script path is written to the environment variable, it can be run anywhere.

**Usage:** Save this code as vasp2exyz, give permissions chmod +x vasp2exyz, then vasp2exyz -i casedir -o xxx.xyz. If you don’t enter -i or -o, you will enter -i alloutcar -o train.xyz by default.

**Example:** vasp2exyz -i alloutcar -o train.xyz.

## Appendix 3: Post-processing analysis

**1）Function:** Computes the RDF between atom i and atoms i and j, time averaging half of the trajectory by default. (**note:** Rely on ovito)

```python
#!/home/xitan/.conda/envs/xitan_conda/bin/python

# Import necessary Python modules
from ovito.data import DislocationNetwork
import time
from ovito.modifiers import SpatialBinningModifier
from ovito.io import import_file, export_file
from ovito.modifiers import ComputePropertyModifier,TimeAveragingModifier,ExpressionSelectionModifier,CoordinationAnalysisModifier
import numpy as np
import argparse

# Initialize argument parser
parser = argparse.ArgumentParser()
parser.add_argument("-i", "--input", help="Input file name", default="XDATCAR")
parser.add_argument("-o", "--output", help="Output file name", default="rdf.txt")
parser.add_argument("-cutoff", "--cutoff", help="Cutoff distance for CoordinationAnalysisModifier", default=5.0, type=float)
parser.add_argument("-bin", "--bin", help="Number of bins for CoordinationAnalysisModifier", default=200, type=int)
args = parser.parse_args()

# Import LAMMPS trajectory file
pipeline = import_file(args.input)

# Calculate the total number of MD frames
num_frames = pipeline.source.num_frames
print("Number of MD frames:", num_frames)

# Calculate the start frame (half the total number of frames)
start_frame = num_frames // 2

# Print the list of input particle types
for t in pipeline.compute().particles.particle_types.types:
    print("Type %i: %s" % (t.id, t.name))

# Calculate partial RDFs
pipeline.modifiers.append(CoordinationAnalysisModifier(cutoff=args.cutoff, number_of_bins=args.bin, partial=True))

# Create a TimeAveragingModifier and specify the frame interval for averaging
averager = TimeAveragingModifier(operate_on='table:coordination-rdf')
averager.interval = (start_frame, num_frames-1)
pipeline.modifiers.append(averager)

# Print the start and end frames used for averaging
print("Averaging from frame {} to frame {}.".format(*averager.interval))

# Compute the pipeline and access the output DataTable
data = pipeline.compute()

# Access the averaged RDF DataTable
rdf_table = data.tables['coordination-rdf[average]']

# The y-property of the data points of the DataTable is now a vectorial property
rdf_names = rdf_table.y.component_names

# Print a list of partial g(r) functions
for component, name in enumerate(rdf_names):
    print("g(r) for pair-wise type combination %s:" % name)
    print(rdf_table.y[:,component])

# Print everything as one combined NumPy table
print(rdf_table.xy())

# Convert the averaged RDF to a NumPy array and save it to a text file
total_rdf = rdf_table.xy()
np.savetxt(args.output, total_rdf)

# Alternatively, use OVITO's export function to save the averaged RDF to a text file
export_file(pipeline, args.output, "txt/table", key="coordination-rdf[average]")
```

**2）Function:** Calculate the time-averaged density for half of the trajectory.(**note:** Rely on ase)

```python
#!/home/xitan/.conda/envs/xitan_conda/bin/python

import argparse
from ase.io import read
from ase import units
import matplotlib.pyplot as plt

# Map software names to trajectory formats
software_to_format = {
    'gpumd': 'extxyz',
    'lammps': 'lammps-dump-text',
    'vasp': 'vasp-xdatcar',
}

# Argument parser
parser = argparse.ArgumentParser(description='Calculate and plot the average density of a system over a specified range of trajectory frames.')
parser.add_argument('-f', '--file', type=str, default='dump.xyz', help='Input file (trajectory). Default is dump.xyz.')
parser.add_argument('-b', '--begin', type=int, default=0, help='Beginning frame for the calculation. Default is 0.')
parser.add_argument('-e', '--end', type=int, default=None, help='End frame for the calculation. Default is None, which means till the last frame.')
parser.add_argument('-soft', '--software', type=str, default='gpumd', help='The name of the software that generated the trajectory file. Default is gpumd.')
args = parser.parse_args()

# Check if the software is supported
if args.software not in software_to_format:
    print(f'Error: The software "{args.software}" is not supported.')
    exit(1)

# Get the format of the trajectory file
format = software_to_format[args.software]

# Load the trajectory
trajectory = read(args.file, index=':', format=format)

# Calculate the frame to start from and end
start_frame = args.begin
end_frame = len(trajectory) if args.end is None else args.end

print(f'The total number of frames in the file: {len(trajectory)}')
print(f'Calculating average density from frame {start_frame} to frame {end_frame}')

# Initialize sum of densities for the specified range
total_density = 0

# Initialize count of frames for the specified range
frame_count = 0

# Initialize list of densities for all frames
all_densities = []

# Loop over all frames in the trajectory
for i, atoms in enumerate(trajectory):
    # Calculate total mass in amu
    total_mass = atoms.get_masses().sum()

    # Convert total mass from amu to grams
    total_mass_grams = total_mass / units.mol  # units.mol is Avogadro's number (in 1/mol), so this gives mass in g

    # Calculate volume of this frame, assuming orthogonal box
    volume_angstrom3 = atoms.get_volume()

    # Convert volume from Angstrom^3 to cm^3
    volume_cm3 = volume_angstrom3 * 1e-24

    # Calculate density (g/cm^3)
    density = total_mass_grams / volume_cm3

    # Add this density to the total if in the specified range
    if start_frame <= i < end_frame:
        total_density += density
        frame_count += 1

    # Add this density to the list of all densities
    all_densities.append(density)

if frame_count == 0:
    print("No valid frames found for the calculation.")
else:
    # Calculate average density
    average_density = total_density / frame_count

    print(f'The average density of the system from frame {start_frame} to frame {end_frame} is: {average_density:.3f} g/cm^3')

    # Save result to txt file
    with open("result.txt", "w") as file:
        file.write(f'The average density of the system from frame {start_frame} to frame {end_frame} is: {average_density:.3f} g/cm^3')

# Plot the density as a function of time for all frames
plt.plot(range(len(trajectory)), all_densities)
plt.xlabel('Frame')
plt.ylabel('Density (g/cm^3)')
plt.title('Density of the system over time')
plt.savefig('density_vs_time.png')
```







